{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0852273",
   "metadata": {},
   "source": [
    "# Title - EDA Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac1d6a",
   "metadata": {},
   "source": [
    "## Is there a correlation between Studio,Genre and Rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced266e6",
   "metadata": {},
   "source": [
    "## How does series runtime vary over time for tv and movies (analyse seperately)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a106e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162b7aa",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "sns.set_palette(\"Set3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b09ff",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_numerical_analysis(numerical_frame: pd.DataFrame ,column:str, new_index:str):\n",
    "    \n",
    "    numerical_data = numerical_frame.loc[:,column]\n",
    "\n",
    "    mean_val = round(numerical_data.mean(),2)\n",
    "    median_val = round(numerical_data.median(),2)\n",
    "    std_val = round(numerical_data.std(),2)\n",
    "    range_val = round(numerical_data.max() - numerical_data.min(),2)  \n",
    "    iqr_val = round(numerical_data.quantile(0.75)-numerical_data.quantile(0.25),2)\n",
    "    skew_val = round(numerical_data.skew(),2)\n",
    "    kurtosis_val = round(numerical_data.kurtosis(),2)\n",
    "    coefficient_of_variance_val = round(((std_val / mean_val) if mean_val != 0 else 0),2) \n",
    "    mode_val = numerical_data.mode().tolist()    \n",
    "    mode_val_string = \"\"\n",
    "\n",
    "    for _ in mode_val:\n",
    "        mode_val_string += str(format(_, \".2f\")) + \",\"\n",
    "\n",
    "\n",
    "\n",
    "    output_frame = pd.DataFrame(\n",
    "        {\"Mean\": [mean_val],\n",
    "         \"Median\": [median_val],\n",
    "         \"Mode\": [mode_val],\n",
    "         \"Standard Deviation\": [std_val],\n",
    "         \"Range\": [range_val],\n",
    "         \"Inter-Quartile Range\": [iqr_val],\n",
    "         \"Skewness\": [skew_val],\n",
    "         \"Kurtosis\": [kurtosis_val],\n",
    "         \"Coefficient of Variance\": [coefficient_of_variance_val]})\n",
    "    output_frame.index = [new_index]\n",
    "   \n",
    "    return(output_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_strip(numerical_frame: pd.DataFrame,column:str):\n",
    "    \n",
    "    q1 = np.percentile(numerical_frame[column], 25)\n",
    "    q3 = np.percentile(numerical_frame[column], 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    outlier_mask = (numerical_frame[column] < lower_bound) | (numerical_frame[column] > upper_bound)\n",
    "\n",
    "    numerical_frame_filtered = numerical_frame[~outlier_mask]\n",
    "\n",
    "    return(numerical_frame_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f2884",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Top_Anime_data.csv\")\n",
    "\n",
    "df.columns = [columns.lower().replace(\" \", \"_\") for columns in df.columns]   ### Anti-whitespace pro snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18883d1",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3964366",
   "metadata": {},
   "source": [
    "filtering df by data type so data inspectionis easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(exclude=\"number\")\n",
    "cat_columns = list(cat.columns)\n",
    "print(f\"The categorical columns of the cat dataframe are :{cat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=\"number\")\n",
    "num_columns = list(num.columns)\n",
    "print(f\"The numerical columns of num dataframe are :{num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c33b0d",
   "metadata": {},
   "source": [
    "### Numeric data check 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_non_null_columns =num.notnull().sum()\n",
    "num_non_null_total = num.notnull().sum().sum()\n",
    "num_non_null_percentage_column = num.notnull().sum() / len(num)\n",
    "num_non_null_percentage_total = (num.notnull().sum().sum()) / (num.size)\n",
    "                                                                            # Count of non-missing values per column:\n",
    "\n",
    "num_dup = num.duplicated()\n",
    "num_dup_total = num.duplicated().sum()                                      # One fewer sum as duplicated returns series not a frame\n",
    "num_na_columns = num.isna().sum()             \n",
    "num_na_total = num.isna().sum().sum()\n",
    "\n",
    "print(f\"\"\"\n",
    "number of non-null values in the frame of numeric data: {num_non_null_total},\n",
    "number of non-null values by column: \\n\\n{num_non_null_columns}\\n\n",
    "\n",
    "precentage of non-null values in the frame of numeric data: {num_non_null_percentage_total * 100},\n",
    "precentage of non-null values by column: \\n\\n{num_non_null_percentage_column * 100}\n",
    "      \n",
    "number of duplicates in the frame of numeric data: {num_dup_total},\n",
    "\n",
    "number of null values in the frame of numeric data:{num_na_total},\n",
    "number of null values by column:\\n\\n{num_na_columns}\\n\"\"\")\n",
    "\n",
    "print(f\"The following rows are duplicates: {','.join(num[num_dup].index )}\") # num_dup is a boolean series which acts as a filter condition\n",
    "print(f\"The following columns have null values: {','.join(num_na_columns[num_na_columns > 0].index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0864cc",
   "metadata": {},
   "source": [
    "### Categoric data check 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81500a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##.strip() on cat\n",
    "\n",
    "stripped = lambda _: _.strip() if isinstance(_, str) else _\n",
    "cat = cat.map(stripped)\n",
    "\n",
    "##\n",
    "\n",
    "cat_non_null_columns = cat.notnull().sum()\n",
    "cat_non_null_total = cat.notnull().sum().sum()\n",
    "cat_non_null_percentage_column = cat.notnull().sum() / len(cat)\n",
    "cat_non_null_percentage_total = (cat.notnull().sum().sum()) / (cat.size)\n",
    "                                                                            # Count of non-missing values per column:\n",
    "\n",
    "cat_dup = cat.duplicated()\n",
    "cat_dup_total = cat.duplicated().sum()                                      # One fewer sum as duplicated returns series not a frame\n",
    "cat_na_columns = cat.isna().sum()             \n",
    "cat_na_total = cat.isna().sum().sum()\n",
    "\n",
    "#cat_spaced_values_total_old = cat.eq(\" \").sum().sum()                      # Old basic whitespace detector\n",
    "\n",
    "cat_spaced_values_columns = cat.astype(str).apply(lambda _ : _.str.match(r'^\\s*$')).sum() \n",
    "cat_spaced_values_total = cat.astype(str).apply(lambda _ : _.str.match(r'^\\s*$')).sum().sum() \n",
    "\n",
    "# Treats every column as data type string, and for every column applies the check that it is not continuos whitespace using the regex\n",
    "# expression r'^\\s*$' and the str.match() method. ^ indicates the start, \\s*checks for coninuos whitespace, and $indicates the end of the expression. \n",
    "\n",
    "print(f\"\"\"\n",
    "number of non-null values in the frame of categoric data: {cat_non_null_total},\n",
    "number of non-null values by column: \\n\\n{cat_non_null_columns}\n",
    "\n",
    "percentage of non-null values in the frame of categoric data: {cat_non_null_percentage_total * 100},\n",
    "percentage of non-null values by column: \\n\\n{cat_non_null_percentage_column * 100}\n",
    "\n",
    "number of duplicates in the frame of categoric data: {cat_dup_total},\n",
    "\n",
    "number of white space values in the frame of categoric data: {cat_spaced_values_total},\n",
    "number of white space values by column: \\n\\n{cat_spaced_values_columns}\n",
    "\n",
    "number of null values in the frame of categoric data:{cat_na_total},\n",
    "number of null values by column:\\n\\n{cat_na_columns}\\n\"\"\")\n",
    "\n",
    "print(f\"The following rows are duplicates: {','.join(cat[cat_dup].index )}\") # cat_dup is a boolean series which acts as a filter condition\n",
    "print(f\"The following columns have null values: {','.join(cat_na_columns[cat_na_columns > 0].index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba57a5a",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709eadc",
   "metadata": {},
   "source": [
    "### Making episodes column numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c2724",
   "metadata": {},
   "source": [
    "All null values set to zero, the zeros can be dropped later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a171142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"episodes\"] = pd.to_numeric(df[\"episodes\"], errors = \"coerce\").fillna(0).astype(int)             #null values saved as zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dc5e1",
   "metadata": {},
   "source": [
    "### Air dates and time on air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last = df[\"aired\"].astype(str).str.split(\" to \", n=1, expand=True)        # first_last is a new dataframe that takes each result from the split as a new column\n",
    "\n",
    "\n",
    "df[\"aired_first\"] = first_last[0].str.strip()\n",
    "df[\"aired_last\"]  = ( \n",
    "    first_last[1]\n",
    "    .str.strip()\n",
    "    .replace(\"?\",\"Dec 31, 2024\")                                                #dataset is for anime in 2024 and made in january 2025, Dec 31, 2024 is being used as end date of dataframe\n",
    "    if first_last.shape[1] > 1 else pd.NA\n",
    "    )\n",
    "\n",
    "## .partion() caused so many problems, sometimes fancy speciifc functions are not worth it\n",
    "\n",
    "# df[[\"japanese\",\"aired_first\",\"aired_last\"]].head(50)                          # Entry 50 one piece is proof this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%b %d, %Y\")\n",
    "\n",
    "df[\"aired_first\"] = pd.to_datetime(df[\"aired_first\"], format=\"%b %d, %Y\")\n",
    "df[\"aired_last\"] = pd.to_datetime(df[\"aired_last\"], format=\"%b %d, %Y\")\n",
    "\n",
    "df[\"years_on_air\"] = (df[\"aired_last\"] - df[\"aired_first\"]).dt.days / 365\n",
    "\n",
    "# df[[\"aired_first\",\"aired_last\",\"years_on_air\"]].head(50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f799702",
   "metadata": {},
   "source": [
    "Studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maybe its better to store studios in list, because we can still sum using indexing, \n",
    "\n",
    "df[\"studios\"] = df[\"studios\"].str.split(\",\").apply(lambda lst: [_.strip() for _ in lst])\n",
    "\n",
    "\n",
    "# mask = df[\"col\"].apply(lambda x: \"b\" in x)        #can be used to find indexes thatt contain a studio\n",
    "# df_filtered = df[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62242b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a517423b",
   "metadata": {},
   "source": [
    "### Splitting genres into genres_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (\n",
    "    df[\"genres\"]\n",
    "    .astype(str)\n",
    "    .str.split(\",\")\n",
    "    .explode()                      # new rows for each new unique value \n",
    "    .str.strip()                    # hidden whitespace destroyer so string slicing doesn't miscount\n",
    "    .replace({\"nan\": pd.NA})        # gets rid of nan, the only \"genre\" that doesn't repeat so isnt affected the same way by the filter\n",
    "    .dropna())\n",
    "\n",
    "tmp = sorted(tmp.unique().tolist())\n",
    "\n",
    "genres_list = []\n",
    "\n",
    "for _ in tmp:\n",
    "    genres_list.append(_[0:(len(_)//2)]) # Removes the duplicated words.\n",
    "\n",
    "# print(genres_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c465f5",
   "metadata": {},
   "source": [
    "Assigning Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbddb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_assignment(dataframe):\n",
    "    for i in genres_list:\n",
    "        df[i] = df[\"genres\"].str.contains(i)\n",
    "\n",
    "genre_assignment(df)\n",
    "\n",
    "## below is a really dirty fix for removing rows that have no genre as none of the methods were working directly on genres.\n",
    "## but it works as the only possible values for rows that had anything in the genres column are True of False. NaN reveals an orignally empty genres column.\n",
    "\n",
    "df = df[~df[\"Horror\"].isna()] \n",
    "df.drop(columns = [\"genres\"])                   #\"genres\" is no longer needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bd6f3",
   "metadata": {},
   "source": [
    "### Replacing null English names with Japanese Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326588d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = df[\"english\"].fillna(df[\"japanese\"])\n",
    "\n",
    "### moving name to the front of the dataframe\n",
    "\n",
    "df = df[[\"name\"] + [c for c in df.columns if c != \"name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84375533",
   "metadata": {},
   "source": [
    "## Data Inspection Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reapplying the snake_case formatting as new columns have been added\n",
    "\n",
    "df.columns = [columns.lower().replace(\" \", \"_\") for columns in df.columns]   ### Anti-whitespace pro snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(exclude=\"number\")\n",
    "cat_columns = list(cat.columns)\n",
    "print(f\"The categorical columns of the cat dataframe are :{cat_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17844a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=\"number\")\n",
    "num_columns = list(num.columns)\n",
    "print(f\"The numerical columns of num dataframe are :{num_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c045b",
   "metadata": {},
   "source": [
    "### Numeric Data Check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bcf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_non_null_columns =num.notnull().sum()\n",
    "num_non_null_total = num.notnull().sum().sum()\n",
    "num_non_null_percentage_column = num.notnull().sum() / len(num)\n",
    "num_non_null_percentage_total = (num.notnull().sum().sum()) / (num.size)\n",
    "                                                                            # Count of non-missing values per column:\n",
    "\n",
    "num_dup = num.duplicated()\n",
    "num_dup_total = num.duplicated().sum()                                      # One fewer sum as duplicated returns series not a frame\n",
    "num_na_columns = num.isna().sum()             \n",
    "num_na_total = num.isna().sum().sum()\n",
    "\n",
    "print(f\"\"\"\n",
    "number of non-null values in the frame of numeric data: {num_non_null_total},\n",
    "number of non-null values by column: \\n\\n{num_non_null_columns}\\n\n",
    "\n",
    "precentage of non-null values in the frame of numeric data: {num_non_null_percentage_total * 100},\n",
    "precentage of non-null values by column: \\n\\n{num_non_null_percentage_column * 100}\n",
    "      \n",
    "number of duplicates in the frame of numeric data: {num_dup_total},\n",
    "\n",
    "number of null values in the frame of numeric data:{num_na_total},\n",
    "number of null values by column:\\n\\n{num_na_columns}\\n\"\"\")\n",
    "\n",
    "print(f\"The following rows are duplicates: {','.join(num[num_dup].index )}\") # num_dup is a boolean series which acts as a filter condition\n",
    "print(f\"The following columns have null values: {','.join(num_na_columns[num_na_columns > 0].index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97bd88",
   "metadata": {},
   "source": [
    "### Catergoric Data Check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "##.strip() on cat\n",
    "\n",
    "stripped = lambda _: _.strip() if isinstance(_, str) else _\n",
    "cat = cat.map(stripped)\n",
    "\n",
    "##\n",
    "\n",
    "cat_non_null_columns = cat.notnull().sum()\n",
    "cat_non_null_total = cat.notnull().sum().sum()\n",
    "cat_non_null_percentage_column = cat.notnull().sum() / len(cat)\n",
    "cat_non_null_percentage_total = (cat.notnull().sum().sum()) / (cat.size)\n",
    "                                                                            # Count of non-missing values per column:\n",
    "\n",
    "cat_dup = cat.duplicated()\n",
    "cat_dup_total = cat.duplicated().sum()                                      # One fewer sum as duplicated returns series not a frame\n",
    "cat_na_columns = cat.isna().sum()             \n",
    "cat_na_total = cat.isna().sum().sum()\n",
    "\n",
    "#cat_spaced_values_total_old = cat.eq(\" \").sum().sum()                      # Old basic whitespace detector\n",
    "\n",
    "cat_spaced_values_columns = cat.astype(str).apply(lambda _ : _.str.match(r'^\\s*$')).sum() \n",
    "cat_spaced_values_total = cat.astype(str).apply(lambda _ : _.str.match(r'^\\s*$')).sum().sum() \n",
    "\n",
    "# Treats every column as data type string, and for every column applies the check that it is not continuos whitespace using the regex\n",
    "# expression r'^\\s*$' and the str.match() method. ^ indicates the start, \\s*checks for coninuos whitespace, and $indicates the end of the expression. \n",
    "\n",
    "print(f\"\"\"\n",
    "number of non-null values in the frame of categoric data: {cat_non_null_total},\n",
    "number of non-null values by column: \\n\\n{cat_non_null_columns}\n",
    "\n",
    "percentage of non-null values in the frame of categoric data: {cat_non_null_percentage_total * 100},\n",
    "percentage of non-null values by column: \\n\\n{cat_non_null_percentage_column * 100}\n",
    "\n",
    "number of duplicates in the frame of categoric data: {cat_dup_total},\n",
    "\n",
    "number of white space values in the frame of categoric data: {cat_spaced_values_total},\n",
    "number of white space values by column: \\n\\n{cat_spaced_values_columns}\n",
    "\n",
    "number of null values in the frame of categoric data:{cat_na_total},\n",
    "number of null values by column:\\n\\n{cat_na_columns}\\n\"\"\")\n",
    "\n",
    "print(f\"The following rows are duplicates: {','.join(cat[cat_dup].index )}\") # cat_dup is a boolean series which acts as a filter condition\n",
    "print(f\"The following columns have null values: {','.join(cat_na_columns[cat_na_columns > 0].index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0287a",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e114da5",
   "metadata": {},
   "source": [
    "### Dropping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "cb1a4a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 771 entries, 0 to 998\n",
      "Data columns (total 28 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   name           770 non-null    object        \n",
      " 1   type           771 non-null    object        \n",
      " 2   status         771 non-null    object        \n",
      " 3   studios        771 non-null    object        \n",
      " 4   source         771 non-null    object        \n",
      " 5   duration       771 non-null    object        \n",
      " 6   rating         771 non-null    object        \n",
      " 7   aired_first    771 non-null    datetime64[ns]\n",
      " 8   aired_last     516 non-null    datetime64[ns]\n",
      " 9   action         771 non-null    bool          \n",
      " 10  adventure      771 non-null    bool          \n",
      " 11  avant_garde    771 non-null    bool          \n",
      " 12  award_winning  771 non-null    bool          \n",
      " 13  boys_love      771 non-null    bool          \n",
      " 14  comedy         771 non-null    bool          \n",
      " 15  drama          771 non-null    bool          \n",
      " 16  ecchi          771 non-null    bool          \n",
      " 17  fantasy        771 non-null    bool          \n",
      " 18  girls_love     771 non-null    bool          \n",
      " 19  gourmet        771 non-null    bool          \n",
      " 20  horror         771 non-null    bool          \n",
      " 21  mystery        771 non-null    bool          \n",
      " 22  romance        771 non-null    bool          \n",
      " 23  sci-fi         771 non-null    bool          \n",
      " 24  slice_of_life  771 non-null    bool          \n",
      " 25  sports         771 non-null    bool          \n",
      " 26  supernatural   771 non-null    bool          \n",
      " 27  suspense       771 non-null    bool          \n",
      "dtypes: bool(19), datetime64[ns](2), object(7)\n",
      "memory usage: 74.5+ KB\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop_cat = [\"description\",\"synonyms\",\"premiered\",\"broadcast\",\"demographic\",\"japanese\",\"english\",\"producers\",\"licensors\",\"genres\",\"aired\"]\n",
    "cat_cleaned = cat.drop(columns = columns_to_drop_cat)\n",
    "#display(cat_cleaned)\n",
    "cat_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e9af840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 771 entries, 0 to 998\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   score         771 non-null    float64\n",
      " 1   rank          771 non-null    int64  \n",
      " 2   episodes      771 non-null    int64  \n",
      " 3   years_on_air  516 non-null    float64\n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop_num = [\"popularity\",\"members\"]\n",
    "num_cleaned = num.drop(columns = columns_to_drop_num)\n",
    "#display(num_cleaned)\n",
    "num_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43682512",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ecedd",
   "metadata": {},
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c515cea",
   "metadata": {},
   "source": [
    "## Bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712c12b",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b1f8f",
   "metadata": {},
   "source": [
    " ## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c83c0",
   "metadata": {},
   "source": [
    " ## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e1c7da",
   "metadata": {},
   "source": [
    " ## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8ee935",
   "metadata": {},
   "source": [
    " ## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84212e0c",
   "metadata": {},
   "source": [
    " ## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ae178",
   "metadata": {},
   "source": [
    " ## Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35285cc",
   "metadata": {},
   "source": [
    " ## Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e605939",
   "metadata": {},
   "source": [
    " ## Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a57d85",
   "metadata": {},
   "source": [
    " ## Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507f05c",
   "metadata": {},
   "source": [
    " ## Q10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
